{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "No7DXraMyfVa"
      },
      "outputs": [],
      "source": [
        "# Notebook 5: Model Interpretability for Amharic NER\n",
        "# ==================================================\n",
        "\n",
        "# Install required packages\n",
        "!pip install shap lime transformers torch\n",
        "\n",
        "import shap\n",
        "import lime\n",
        "from lime.lime_text import LimeTextExplainer\n",
        "from transformers import AutoTokenizer, AutoModelForTokenClassification, pipeline\n",
        "\n",
        "# ==============================\n",
        "# 1. Load Trained Model\n",
        "# ==============================\n",
        "model_name = \"./ner_model_final\"  # Path from Notebook 3\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForTokenClassification.from_pretrained(model_name)\n",
        "\n",
        "# Hugging Face NER pipeline\n",
        "ner_pipeline = pipeline(\"ner\", model=model, tokenizer=tokenizer, grouped_entities=True)\n",
        "\n",
        "# ==============================\n",
        "# 2. Example Message for Interpretation\n",
        "# ==============================\n",
        "example_text = \"ሙሉ ቁርስ በ200 ብር በአዲስ አበባ\"\n",
        "\n",
        "# ==============================\n",
        "# 3. SHAP Interpretation\n",
        "# ==============================\n",
        "# SHAP uses background dataset for reference\n",
        "background_texts = [\"የቤት እቃዎች ማስታወቂያ\", \"በ100 ብር እቃ ማስታወቂያ\"]  # small sample\n",
        "explainer = shap.Explainer(ner_pipeline, background_texts)\n",
        "\n",
        "shap_values = explainer([example_text])\n",
        "shap.plots.text(shap_values[0])\n",
        "\n",
        "# ==============================\n",
        "# 4. LIME Interpretation\n",
        "# ==============================\n",
        "class_names = [\"O\", \"B-Product\", \"I-Product\", \"B-LOC\", \"I-LOC\", \"B-PRICE\", \"I-PRICE\"]\n",
        "explainer = LimeTextExplainer(class_names=class_names)\n",
        "\n",
        "# Define prediction function for LIME\n",
        "def predict_fn(texts):\n",
        "    outputs = []\n",
        "    for t in texts:\n",
        "        ner_results = ner_pipeline(t)\n",
        "        # Map NER entities to class probabilities (simplified)\n",
        "        probs = [0] * len(class_names)\n",
        "        for res in ner_results:\n",
        "            if res['entity_group'] in class_names:\n",
        "                idx = class_names.index(res['entity_group'])\n",
        "                probs[idx] = res['score']\n",
        "        outputs.append(probs)\n",
        "    return np.array(outputs)\n",
        "\n",
        "# Run LIME explanation\n",
        "exp = explainer.explain_instance(example_text, predict_fn, num_features=10)\n",
        "exp.show_in_notebook(text=True)\n"
      ]
    }
  ]
}